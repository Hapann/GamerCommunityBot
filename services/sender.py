import os
import asyncio
import re
from datetime import datetime
import dateutil.parser
from aiogram import Bot
from sqlalchemy import select
from database.db import AsyncSessionLocal
from database.models import News, SentNews
from services.rss_reader import get_all_rss_news
from services.gigachat import generate_gigachat_summary
from logger.logger import logger

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===
BOT_TOKEN = os.getenv("TOKEN")
CHAT_ID = int(os.getenv("CHAT_ID"))
TOPIC_ID = os.getenv("TOPIC_ID")
TOPIC_ID = int(TOPIC_ID) if TOPIC_ID else None

bot = Bot(token=BOT_TOKEN)

MAX_RETRIES = 3          # –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–∏ —Å–±–æ–µ
RETRY_DELAY = 30         # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏ (—Å–µ–∫)
DELAY_BETWEEN_NEWS = 10  # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø—É–±–ª–∏–∫–∞—Ü–∏—è–º–∏ (—Å–µ–∫)


# === –£—Ç–∏–ª–∏—Ç—ã ===
def to_datetime_safe(value):
    try:
        if not value:
            return datetime.utcnow()
        return dateutil.parser.parse(value)
    except Exception:
        return datetime.utcnow()


def sanitize_llm_reply(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ –º–µ—Ç–∫–∏ –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç –ø–æ–¥ Telegram."""
    cleaned = text.strip()
    cleaned = re.sub(r"---(PROMPT|REPLY)\s+(START|END)---", "", cleaned)
    cleaned = re.sub(r"^###\s*", "üì∞ ", cleaned, flags=re.MULTILINE)
    escape_chars = r"_*[]()~`>#+-=|{}.!\\"
    cleaned = re.sub(f"([{re.escape(escape_chars)}])", r"\\\1", cleaned)
    return cleaned.strip()


async def sync_rss_to_db():
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ RSS."""
    news_list = await get_all_rss_news()
    new_count = 0

    async with AsyncSessionLocal() as session:
        for item in news_list:
            stmt = select(News).where(News.url == item["link"])
            result = await session.execute(stmt)
            exists = result.scalar_one_or_none()
            if exists:
                continue

            published_at = to_datetime_safe(item.get("published") or item.get("updated"))
            news = News(
                title=item["title"],
                url=item["link"],
                published_at=published_at,
            )
            session.add(news)
            new_count += 1

        await session.commit()

    logger.info(f"üì∞ –î–æ–±–∞–≤–ª–µ–Ω–æ {new_count} –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π.")
    return new_count


# === –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ ===
async def send_new_news():
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ –ø—É–±–ª–∏–∫—É–µ—Ç –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏."""
    await sync_rss_to_db()

    async with AsyncSessionLocal() as session:
        stmt = (
            select(News)
            .outerjoin(SentNews, SentNews.news_id == News.id)
            .where(SentNews.id.is_(None))
        )
        result = await session.execute(stmt)
        unsent_news = result.scalars().all()

    if not unsent_news:
        logger.info("üò¥ –ù–µ—Ç –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.")
        return

    logger.info(f"üåê –ù–∞–π–¥–µ–Ω–æ {len(unsent_news)} –Ω–æ–≤–æ—Å—Ç–µ–π. –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...")

    for news in unsent_news:
        success = False

        for attempt in range(1, MAX_RETRIES + 1):
            try:
                logger.info(f"üß† [{attempt}/{MAX_RETRIES}] –ê–Ω–∞–ª–∏–∑: {news.url}")
                generated_text = generate_gigachat_summary(news.url)

                if not generated_text:
                    raise ValueError("LLM –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")

                clean_text = sanitize_llm_reply(generated_text)
                logger.debug(f"–¢–µ–∫—Å—Ç –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ ({len(clean_text)} —Å–∏–º–≤.): {clean_text[:100]!r}")

                if len(clean_text) < 50:
                    raise ValueError("–û—Ç–≤–µ—Ç –æ—Ç LLM —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")

                logger.info(f"üöÄ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram: {news.title[:60]}...")

                try:
                    # --- —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ ---
                    send_kwargs = dict(
                        chat_id=CHAT_ID,
                        text=clean_text,
                        parse_mode="MarkdownV2",
                        disable_web_page_preview=True,
                    )

                    if TOPIC_ID:
                        send_kwargs["message_thread_id"] = TOPIC_ID

                    await bot.send_message(**send_kwargs)

                except Exception as parse_err:
                    logger.error(f"üí• –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Markdown: {parse_err}, –ø—Ä–æ–±—É–µ–º –±–µ–∑ parse_mode.")
                    send_kwargs.pop("parse_mode", None)
                    await bot.send_message(**send_kwargs)

                # ‚úÖ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–∫—Ç –æ—Ç–ø—Ä–∞–≤–∫–∏
                async with AsyncSessionLocal() as session:
                    sent = SentNews(user_id=None, news_id=news.id, sent_at=datetime.utcnow())
                    session.add(sent)
                    await session.commit()

                logger.info(f"‚úÖ –ù–æ–≤–æ—Å—Ç—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞: {news.url}")
                success = True
                break

            except Exception as e:
                logger.error(f"‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt} –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è {news.url}: {e}")
                if attempt < MAX_RETRIES:
                    logger.info(f"‚è≥ –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {RETRY_DELAY} —Å–µ–∫...")
                    await asyncio.sleep(RETRY_DELAY)
                else:
                    logger.error(f"üíÄ –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –¥–ª—è {news.url}")

        if not success:
            logger.warning(f"‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç—å {news.url} –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω—É—é –ø–æ–ø—ã—Ç–∫—É.")
        else:
            await asyncio.sleep(DELAY_BETWEEN_NEWS)

    logger.info("üèÅ –¶–∏–∫–ª –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–≤–µ—Ä—à—ë–Ω.")
